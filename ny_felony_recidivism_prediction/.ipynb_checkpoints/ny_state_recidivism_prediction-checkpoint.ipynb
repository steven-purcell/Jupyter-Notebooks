{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GradBoost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>County of Indictment</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age at Release</th>\n",
       "      <th>Return Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83334</th>\n",
       "      <td>2009</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>46</td>\n",
       "      <td>New Felony Offense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118617</th>\n",
       "      <td>2008</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>MALE</td>\n",
       "      <td>44</td>\n",
       "      <td>Not Returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70959</th>\n",
       "      <td>2010</td>\n",
       "      <td>WAYNE</td>\n",
       "      <td>MALE</td>\n",
       "      <td>29</td>\n",
       "      <td>Not Returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37902</th>\n",
       "      <td>2011</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>MALE</td>\n",
       "      <td>50</td>\n",
       "      <td>Not Returned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>2012</td>\n",
       "      <td>BROOME</td>\n",
       "      <td>MALE</td>\n",
       "      <td>30</td>\n",
       "      <td>Not Returned</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Release Year County of Indictment  Gender  Age at Release  \\\n",
       "83334           2009             NEW YORK  FEMALE              46   \n",
       "118617          2008               QUEENS    MALE              44   \n",
       "70959           2010                WAYNE    MALE              29   \n",
       "37902           2011             NEW YORK    MALE              50   \n",
       "3124            2012               BROOME    MALE              30   \n",
       "\n",
       "             Return Status  \n",
       "83334   New Felony Offense  \n",
       "118617        Not Returned  \n",
       "70959         Not Returned  \n",
       "37902         Not Returned  \n",
       "3124          Not Returned  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\".\\\\Recidivism__Beginning_2008.csv\")\n",
    "data = data[data['Return Status']!='Returned Parole Violation']\n",
    "data.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare replacements for categorical variables\n",
    "county_labels = data['County of Indictment'].astype('category').cat.categories.tolist()\n",
    "replace_county = {'County of Indictment' : {k: v for k,v in zip(county_labels,list(range(1,len(county_labels)+1)))}}\n",
    "\n",
    "gender_labels = data['Gender'].astype('category').cat.categories.tolist()\n",
    "replace_gender = {'Gender' : {'FEMALE': 0, 'MALE': 1}}\n",
    "\n",
    "replace_status = {'Return Status':{'Returned Parole Violation': 1, 'New Felony Offense': 1, 'Not Returned': 0}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    72477\n",
       "0    72477\n",
       "Name: Return Status, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy and add dummies for categorical variables\n",
    "data_w_dummies = data.copy()\n",
    "data_w_dummies.replace(replace_county, inplace=True)\n",
    "data_w_dummies.replace(replace_gender, inplace=True)\n",
    "data_w_dummies.replace(replace_status, inplace=True)\n",
    "# data_w_dummies = data_w_dummies.drop('Release Year', axis=1)\n",
    "# data_w_dummies = data_w_dummies.drop('County of Indictment', axis=1)\n",
    "# data_w_dummies = data_w_dummies[data_w_dummies['Gender']==1]\n",
    "# data_w_dummies = data_w_dummies.drop('Gender', axis=1)\n",
    "\n",
    "df_majority = data_w_dummies[data_w_dummies['Return Status']==0]\n",
    "df_minority = data_w_dummies[data_w_dummies['Return Status']==1]\n",
    "\n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=72477,    # to match majority class\n",
    "                                 random_state=42) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "data_w_dummies = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "data_w_dummies['Return Status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = data_w_dummies.iloc[:,0:-1]\n",
    "y_data = data_w_dummies.iloc[:,-1:]\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(x_data, y_data, test_size=.20,\n",
    "                                                    random_state=numpy.random.randint(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steve\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Correct</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>False Negative</th>\n",
       "      <th>False Positive</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>True Negative</th>\n",
       "      <th>True Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.584537</td>\n",
       "      <td>0.584216</td>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>16937</td>\n",
       "      <td>0.606053</td>\n",
       "      <td>5144</td>\n",
       "      <td>6910</td>\n",
       "      <td>12054</td>\n",
       "      <td>0.572982</td>\n",
       "      <td>0.643174</td>\n",
       "      <td>0.525901</td>\n",
       "      <td>0.643174</td>\n",
       "      <td>7665</td>\n",
       "      <td>9272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        AUC  Accuracy                  Classifier  Correct  F1-Score  \\\n",
       "0  0.584537  0.584216  GradientBoostingClassifier    16937  0.606053   \n",
       "\n",
       "   False Negative  False Positive  Incorrect  Precision    Recall  \\\n",
       "0            5144            6910      12054   0.572982  0.643174   \n",
       "\n",
       "   Sensitivity  Specificity  True Negative  True Positive  \n",
       "0     0.525901     0.643174           7665           9272  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GradBoost\n",
    "scores, mean_auc, mean_tpr, mean_spec, mean_prec, mean_rec, mean_f1 = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "cm0 = numpy.zeros((2, 2))\n",
    "\n",
    "fit_data = clf.fit(X_train, y_train)\n",
    "preds = clf.predict(X_cv)\n",
    "\n",
    "'''Calculate performance metrics'''\n",
    "scores = metrics.accuracy_score(y_cv, preds)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_cv, preds, pos_label=1)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "mean_auc = roc_auc\n",
    "cm = metrics.confusion_matrix(y_cv, preds)\n",
    "mean_tpr = float(cm[0][0]) / numpy.sum(cm[0])\n",
    "cm0 = cm\n",
    "prec, rec, _, _ = metrics.precision_recall_fscore_support(y_cv, preds, pos_label=1, average='binary')\n",
    "mean_prec = numpy.mean(prec)\n",
    "mean_rec = numpy.mean(rec)\n",
    "mean_spec = rec\n",
    "mean_f1 = 2 * numpy.mean(prec) * numpy.mean(rec) / (numpy.mean(prec) + numpy.mean(rec))\n",
    "\n",
    "metrics_dict = {'Accuracy': float(scores),\n",
    "            'AUC': float(mean_auc),\n",
    "            'Sensitivity': float(mean_tpr),\n",
    "            'Specificity': float(mean_spec),\n",
    "            'Precision': float(mean_prec),\n",
    "            'Recall': float(mean_rec),\n",
    "            'F1-Score': float(mean_f1),\n",
    "            'True Positive': int(cm0[1, 1]),\n",
    "            'True Negative': int(cm0[0, 0]),\n",
    "            'False Positive': int(cm0[0, 1]),\n",
    "            'False Negative': int(cm0[1, 0])}\n",
    "\n",
    "metrics_dict = {'Accuracy': float(scores),\n",
    "            'AUC': float(mean_auc),\n",
    "            'Sensitivity': float(mean_tpr),\n",
    "            'Specificity': float(mean_spec),\n",
    "            'Precision': float(mean_prec),\n",
    "            'Recall': float(mean_rec),\n",
    "            'F1-Score': float(mean_f1),\n",
    "            'True Positive': int(cm0[1, 1]),\n",
    "            'True Negative': int(cm0[0, 0]),\n",
    "            'False Positive': int(cm0[0, 1]),\n",
    "            'False Negative': int(cm0[1, 0]),\n",
    "            'Incorrect': int(cm0[0, 1]) + int(cm0[1, 0]),\n",
    "            'Correct': int(cm0[1, 1]) + int(cm0[0, 0])}\n",
    "metrics_dict['Classifier'] = str(clf).split('(')[0]\n",
    "metrics_df = pd.DataFrame.from_records(metrics_dict, index=[0], exclude=None, columns=None, coerce_float=False, nrows=None)\n",
    "metrics_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
